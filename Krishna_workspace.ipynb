{"cells":[{"cell_type":"code","source":["PySpark Groupby Explained with Example\nSimilar to SQL GROUP BY clause, PySpark groupBy() function is used to collect the identical data into groups on DataFrame and perform count, sum, avg, min, max functions on the grouped data. In this article, I will explain several groupBy() examples using PySpark (Spark with Python).\nsimpleData = [(\"James\",\"Sales\",\"NY\",90000,34,10000),\n    (\"Michael\",\"Sales\",\"NY\",86000,56,20000),\n    (\"Robert\",\"Sales\",\"CA\",81000,30,23000),\n    (\"Maria\",\"Finance\",\"CA\",90000,24,23000),\n    (\"Raman\",\"Finance\",\"CA\",99000,40,24000),\n    (\"Scott\",\"Finance\",\"NY\",83000,36,19000),\n    (\"Jen\",\"Finance\",\"NY\",79000,53,15000),\n    (\"Jeff\",\"Marketing\",\"CA\",80000,25,18000),\n    (\"Kumar\",\"Marketing\",\"NY\",91000,50,21000)\n  ]\n\nschema = [\"employee_name\",\"department\",\"state\",\"salary\",\"age\",\"bonus\"]\ndf = spark.createDataFrame(data=simpleData, schema = schema)\ndf.printSchema()\ndf.show(truncate=False)\n2. PySpark groupBy on DataFrame Columns\nLet’s do the groupBy() on department column of DataFrame and then find the sum of salary for each department using sum() function.\ndf.groupBy(\"department\").sum(\"salary\").show(truncate=False)\nSimilarly, we can calculate the number of employees in each department using.\ndf.groupBy(\"department\").count()\nCalculate the minimum salary of each department using min()\ndf.groupBy(\"department\").min(\"salary\")\nCalculate the maximin salary of each department using max()\ndf.groupBy(\"department\").max(\"salary\")\nCalculate the average salary of each department using avg()\ndf.groupBy(\"department\").avg( \"salary\")\nCalculate the mean salary of each department using mean()\ndf.groupBy(\"department\").mean( \"salary\") "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6427001f-9617-4cb9-948c-ccc799866a06"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["import pyspark\nsimpleData = [(\"James\",\"Sales\",\"NY\",90000,34,10000),\n    (\"Michael\",\"Sales\",\"NY\",86000,56,20000),\n    (\"Robert\",\"Sales\",\"CA\",81000,30,23000),\n    (\"Maria\",\"Finance\",\"CA\",90000,24,23000),\n    (\"Raman\",\"Finance\",\"CA\",99000,40,24000),\n    (\"Scott\",\"Finance\",\"NY\",83000,36,19000),\n    (\"Jen\",\"Finance\",\"NY\",79000,53,15000),\n    (\"Jeff\",\"Marketing\",\"CA\",80000,25,18000),\n    (\"Kumar\",\"Marketing\",\"NY\",91000,50,21000)\n  ]\nschema = [\"employee_name\",\"department\",\"state\",\"salary\",\"age\",\"bonus\"]\ndf200 = spark.createDataFrame(data = simpleData,schema = schema)\ndf200.printSchema()\ndf200.show()\ndf200.groupBy(\"department\").sum(\"salary\").show()\ndf200.groupBy(\"department\").count().show()\ndf200.groupBy(\"department\").min(\"salary\").show()\ndf200.groupBy(\"department\").max(\"salary\").show()\ndf200.groupBy(\"department\").avg(\"salary\").show()\ndf200.groupBy(\"department\").mean(\"salary\").show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2b2e4588-c87a-48ae-8dba-6bc588f3b105"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- employee_name: string (nullable = true)\n |-- department: string (nullable = true)\n |-- state: string (nullable = true)\n |-- salary: long (nullable = true)\n |-- age: long (nullable = true)\n |-- bonus: long (nullable = true)\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|        James|     Sales|   NY| 90000| 34|10000|\n|      Michael|     Sales|   NY| 86000| 56|20000|\n|       Robert|     Sales|   CA| 81000| 30|23000|\n|        Maria|   Finance|   CA| 90000| 24|23000|\n|        Raman|   Finance|   CA| 99000| 40|24000|\n|        Scott|   Finance|   NY| 83000| 36|19000|\n|          Jen|   Finance|   NY| 79000| 53|15000|\n|         Jeff| Marketing|   CA| 80000| 25|18000|\n|        Kumar| Marketing|   NY| 91000| 50|21000|\n+-------------+----------+-----+------+---+-----+\n\n+----------+-----------+\n|department|sum(salary)|\n+----------+-----------+\n|     Sales|     257000|\n|   Finance|     351000|\n| Marketing|     171000|\n+----------+-----------+\n\n+----------+-----+\n|department|count|\n+----------+-----+\n|     Sales|    3|\n|   Finance|    4|\n| Marketing|    2|\n+----------+-----+\n\n+----------+-----------+\n|department|min(salary)|\n+----------+-----------+\n|     Sales|      81000|\n|   Finance|      79000|\n| Marketing|      80000|\n+----------+-----------+\n\n+----------+-----------+\n|department|max(salary)|\n+----------+-----------+\n|     Sales|      90000|\n|   Finance|      99000|\n| Marketing|      91000|\n+----------+-----------+\n\n+----------+-----------------+\n|department|      avg(salary)|\n+----------+-----------------+\n|     Sales|85666.66666666667|\n|   Finance|          87750.0|\n| Marketing|          85500.0|\n+----------+-----------------+\n\n+----------+-----------------+\n|department|      avg(salary)|\n+----------+-----------------+\n|     Sales|85666.66666666667|\n|   Finance|          87750.0|\n| Marketing|          85500.0|\n+----------+-----------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- employee_name: string (nullable = true)\n |-- department: string (nullable = true)\n |-- state: string (nullable = true)\n |-- salary: long (nullable = true)\n |-- age: long (nullable = true)\n |-- bonus: long (nullable = true)\n\n+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|        James|     Sales|   NY| 90000| 34|10000|\n|      Michael|     Sales|   NY| 86000| 56|20000|\n|       Robert|     Sales|   CA| 81000| 30|23000|\n|        Maria|   Finance|   CA| 90000| 24|23000|\n|        Raman|   Finance|   CA| 99000| 40|24000|\n|        Scott|   Finance|   NY| 83000| 36|19000|\n|          Jen|   Finance|   NY| 79000| 53|15000|\n|         Jeff| Marketing|   CA| 80000| 25|18000|\n|        Kumar| Marketing|   NY| 91000| 50|21000|\n+-------------+----------+-----+------+---+-----+\n\n+----------+-----------+\n|department|sum(salary)|\n+----------+-----------+\n|     Sales|     257000|\n|   Finance|     351000|\n| Marketing|     171000|\n+----------+-----------+\n\n+----------+-----+\n|department|count|\n+----------+-----+\n|     Sales|    3|\n|   Finance|    4|\n| Marketing|    2|\n+----------+-----+\n\n+----------+-----------+\n|department|min(salary)|\n+----------+-----------+\n|     Sales|      81000|\n|   Finance|      79000|\n| Marketing|      80000|\n+----------+-----------+\n\n+----------+-----------+\n|department|max(salary)|\n+----------+-----------+\n|     Sales|      90000|\n|   Finance|      99000|\n| Marketing|      91000|\n+----------+-----------+\n\n+----------+-----------------+\n|department|      avg(salary)|\n+----------+-----------------+\n|     Sales|85666.66666666667|\n|   Finance|          87750.0|\n| Marketing|          85500.0|\n+----------+-----------------+\n\n+----------+-----------------+\n|department|      avg(salary)|\n+----------+-----------------+\n|     Sales|85666.66666666667|\n|   Finance|          87750.0|\n| Marketing|          85500.0|\n+----------+-----------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["3. Using Multiple columns\nSimilarly, we can also run groupBy and aggregate on two or more DataFrame columns, below example does group by on department,state and does sum() on salary and bonus columns.\n//GroupBy on multiple columns\ndf.groupBy(\"department\",\"state\") \\\n    .sum(\"salary\",\"bonus\") \\\n    .show(false)\n\n4. Running more aggregates at a time\nUsing agg() aggregate function we can calculate many aggregations at a time on a single statement using SQL functions sum(), avg(), min(), max() mean() e.t.c. In order to use these, we should import \"from pyspark.sql.functions import sum,avg,max,min,mean,count\"\nfrom pyspark.sql.functions import sum,avg,max\ndf.groupBy(\"department\") \\\n    .agg(sum(\"salary\").alias(\"sum_salary\"), \\\n         avg(\"salary\").alias(\"avg_salary\"), \\\n         sum(\"bonus\").alias(\"sum_bonus\"), \\\n         max(\"bonus\").alias(\"max_bonus\") \\\n     ) \\\n    .show(truncate=False)\nThis example does group on department column and calculates sum() and avg() of salary for each department and calculates sum() and max() of bonus for each department.\n5. Using filter on aggregate data\nSimilar to SQL “HAVING” clause, On PySpark DataFrame we can use either where() or filter() function to filter the rows of aggregated data.\nfrom pyspark.sql.functions import sum,avg,max\ndf.groupBy(\"department\") \\\n    .agg(sum(\"salary\").alias(\"sum_salary\"), \\\n      avg(\"salary\").alias(\"avg_salary\"), \\\n      sum(\"bonus\").alias(\"sum_bonus\"), \\\n      max(\"bonus\").alias(\"max_bonus\")) \\\n    .where(col(\"sum_bonus\") >= 50000) \\\n    .show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c1fe2186-ce09-4b9e-8987-fffc309b38b2"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import sum,min,max,avg,col\ndf200.groupBy(\"department\",\"state\").sum(\"salary\",\"bonus\").show(truncate = False)\ndf200.groupBy(\"department\").agg(sum(\"salary\").alias(\"sum\"),\\\n                               avg(\"salary\").alias(\"salary\"),\\\n                                min(\"salary\").alias(\"min\"),\\\n                                max(\"salary\").alias(\"max\")\n                               ).show()\ndf200.groupBy(\"department\").agg(sum(\"salary\").alias(\"sum_salary\"),avg(\"salary\").alias(\"avg_salary\"),\n                                sum(\"bonus\").alias(\"bonus_sum\"),max(\"bonus\").alias(\"max_bonus\")).where(col(\"bonus_sum\")>=50000).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"55c7b460-1ee5-476c-8aa6-3c1806b5a997"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+----------+-----+-----------+----------+\n|department|state|sum(salary)|sum(bonus)|\n+----------+-----+-----------+----------+\n|Sales     |NY   |176000     |30000     |\n|Sales     |CA   |81000      |23000     |\n|Finance   |CA   |189000     |47000     |\n|Finance   |NY   |162000     |34000     |\n|Marketing |NY   |91000      |21000     |\n|Marketing |CA   |80000      |18000     |\n+----------+-----+-----------+----------+\n\n+----------+------+-----------------+-----+-----+\n|department|   sum|           salary|  min|  max|\n+----------+------+-----------------+-----+-----+\n|     Sales|257000|85666.66666666667|81000|90000|\n|   Finance|351000|          87750.0|79000|99000|\n| Marketing|171000|          85500.0|80000|91000|\n+----------+------+-----------------+-----+-----+\n\n+----------+----------+-----------------+---------+---------+\n|department|sum_salary|       avg_salary|bonus_sum|max_bonus|\n+----------+----------+-----------------+---------+---------+\n|     Sales|    257000|85666.66666666667|    53000|    23000|\n|   Finance|    351000|          87750.0|    81000|    24000|\n+----------+----------+-----------------+---------+---------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------+-----+-----------+----------+\n|department|state|sum(salary)|sum(bonus)|\n+----------+-----+-----------+----------+\n|Sales     |NY   |176000     |30000     |\n|Sales     |CA   |81000      |23000     |\n|Finance   |CA   |189000     |47000     |\n|Finance   |NY   |162000     |34000     |\n|Marketing |NY   |91000      |21000     |\n|Marketing |CA   |80000      |18000     |\n+----------+-----+-----------+----------+\n\n+----------+------+-----------------+-----+-----+\n|department|   sum|           salary|  min|  max|\n+----------+------+-----------------+-----+-----+\n|     Sales|257000|85666.66666666667|81000|90000|\n|   Finance|351000|          87750.0|79000|99000|\n| Marketing|171000|          85500.0|80000|91000|\n+----------+------+-----------------+-----+-----+\n\n+----------+----------+-----------------+---------+---------+\n|department|sum_salary|       avg_salary|bonus_sum|max_bonus|\n+----------+----------+-----------------+---------+---------+\n|     Sales|    257000|85666.66666666667|    53000|    23000|\n|   Finance|    351000|          87750.0|    81000|    24000|\n+----------+----------+-----------------+---------+---------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7f2d6eac-857b-41d8-8570-2e741b64bdd5"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Krishna_workspace","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":98536813389210}},"nbformat":4,"nbformat_minor":0}
