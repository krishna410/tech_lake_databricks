{"cells":[{"cell_type":"code","source":["columns = [\"language\",\"user_count\"]\ndata = [(\"java\",\"20000\"),(\"python\",\"10000\"),(\"scala\",\"3000\")]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"799dc7b1-77ed-479d-81a0-415f2011bb35"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["first, letâ€™s create a Spark RDD from a collection List by calling parallelize() function from SparkContext . We would need this rdd object for all our examples below.\nspark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\nrdd = spark.sparkContext.parallelize(data)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"125935b7-4878-4636-abc7-74c0dd87633c"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["import pyspark\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\nrdd = spark.sparkContext.parallelize(data)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"989a6f68-cc4c-4a41-b58d-aee3bdb22a24"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["dfFromRDD1= rdd.toDF()\ndfFromRDD1.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e77cee2b-68d1-4090-be40-1789e9469889"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- _1: string (nullable = true)\n |-- _2: string (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- _1: string (nullable = true)\n |-- _2: string (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["columns = [\"language\",\"user_count\"]\ndfFromrRDD = rdd.toDF(columns)\ndfFromrRDD.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6862abdd-4a53-450c-ae41-387920a39c39"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- language: string (nullable = true)\n |-- user_count: string (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- language: string (nullable = true)\n |-- user_count: string (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["\ndfFromRDD2 = spark.createDataFrame(rdd).toDF(*columns)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"34707d93-dad1-4384-97f7-ef7b74910d65"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["\ndfFromData2 = spark.createDataFrame(data).toDF(*columns)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"36ff40e6-72e6-42ff-ba2f-f98c95f6755f"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["import pyspark\nfrom pyspark.sql import Row\nrowData = map(lambda x: Row(*x), data) \ndfFromData3 = spark.createDataFrame(rowData,columns)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5063797c-fdd0-488a-a63b-38b64b8a6a8c"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["\nfrom pyspark.sql.types import StructType,StructField, StringType, IntegerType\ndata2 = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\n    (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",4000),\n    (\"Robert\",\"\",\"Williams\",\"42114\",\"M\",4000),\n    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n    (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)\n  ]\n\nschema = StructType([ \\\n    StructField(\"firstname\",StringType(),True), \\\n    StructField(\"middlename\",StringType(),True), \\\n    StructField(\"lastname\",StringType(),True), \\\n    StructField(\"id\", StringType(), True), \\\n    StructField(\"gender\", StringType(), True), \\\n    StructField(\"salary\", IntegerType(), True) \\\n  ])\n \ndf = spark.createDataFrame(data=data2,schema=schema)\ndf.printSchema()\ndf.show(truncate=False)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8b80ccf7-aff3-4da3-b08c-5df96c3ceaa6"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["import pyspark\nfrom pyspark.sql.types import StructType,StructField,StringType,IntegerType\ndata2 = [(\"James\",\"\",\"Smith\",36636,\"M\",3000),\n    (\"Michael\",\"Rose\",\"\",40288,\"M\",4000),\n    (\"Robert\",\"\",\"Williams\",42114,\"M\",4000),\n    (\"Maria\",\"Anne\",\"Jones\",39192,\"F\",4000),\n    (\"Jen\",\"Mary\",\"Brown\",1234,\"F\",-1)]\n\nschema = StructType([\\\n         StructField(\"firstname\",StringType(),True), \\\n         StructField(\"middlename\",StringType(),True), \\\n         StructField(\"lastname\",StringType(),True), \\\n         StructField(\"id\",IntegerType(),True), \\\n         StructField(\"gender\",StringType(),True), \\\n         StructField(\"salary\",IntegerType(),True) \\\n                 ])\ndf = spark.createDataFrame(data = data2,schema=schema)\ndf.printSchema()\ndf.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0067fa84-9bbd-4521-a90f-5e64b21587c2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- firstname: string (nullable = true)\n |-- middlename: string (nullable = true)\n |-- lastname: string (nullable = true)\n |-- id: integer (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: integer (nullable = true)\n\n+---------+----------+--------+-----+------+------+\n|firstname|middlename|lastname|id   |gender|salary|\n+---------+----------+--------+-----+------+------+\n|James    |          |Smith   |36636|M     |3000  |\n|Michael  |Rose      |        |40288|M     |4000  |\n|Robert   |          |Williams|42114|M     |4000  |\n|Maria    |Anne      |Jones   |39192|F     |4000  |\n|Jen      |Mary      |Brown   |1234 |F     |-1    |\n+---------+----------+--------+-----+------+------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- firstname: string (nullable = true)\n |-- middlename: string (nullable = true)\n |-- lastname: string (nullable = true)\n |-- id: integer (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: integer (nullable = true)\n\n+---------+----------+--------+-----+------+------+\n|firstname|middlename|lastname|id   |gender|salary|\n+---------+----------+--------+-----+------+------+\n|James    |          |Smith   |36636|M     |3000  |\n|Michael  |Rose      |        |40288|M     |4000  |\n|Robert   |          |Williams|42114|M     |4000  |\n|Maria    |Anne      |Jones   |39192|F     |4000  |\n|Jen      |Mary      |Brown   |1234 |F     |-1    |\n+---------+----------+--------+-----+------+------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ce2bf3e2-ebc8-48e3-9701-6d25c9aef974"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Test_Notebook","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2639287515226076}},"nbformat":4,"nbformat_minor":0}
