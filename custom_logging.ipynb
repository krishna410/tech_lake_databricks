{"cells":[{"cell_type":"code","source":["spark.conf.set(\"fs.azure.account.key.sravanazuredatalake.dfs.core.windows.net\",\"oh48WmsBnYM1BJMe9xfhpMOYgGUKQobLgPxGyRpYSgE7RIkif2r9CalaFVxaCoQRHn8TQ10S4YJJ+AStQm3qEA==\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"2166218c-a045-4cf4-868a-639eaa8129e5","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["import logging\nimport time\nimport datetime\n\n\"\"\"this program using for custom logging in pyspark and it will create a log file\"\"\"\nfile_date = datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d-%H-%M-%S')\n#print(file_date)\n# this custome log information can't store directly into dbfs location. first create the temp folder and then move the temp folder to dbfs filestore.\np_dir = '/tmp/'\np_filename = 'custom_log'+file_date+'.log'\np_log_file = p_dir + p_filename\nprint(p_log_file)\n#create logger with custome log \nlogger = logging.getLogger('log4j')\nlogger.setLevel(logging.DEBUG)\n# create file handler which logs even debug messages\nfh = logging.FileHandler(p_log_file,mode='a')\n#create console handler with a higher log levels\nch= logging.StreamHandler()\nch.setLevel(logging.DEBUG)\n#creater formater and add it to the handlers\nformatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n# setting for ignorning the frequent log information\n#logging.getLogger(\"py4j\").setLevel(logging.ERROR)\n#tell the handler to use this format\n#fh(file Handler)\nfh.setFormatter(formatter)\n#ch (console hhandler)\nch.setFormatter(formatter)\n#clearing the old frequent log information to ignore that\nif (logger.hasHandlers()):\n    logger.handlers.clear()\n# add the handler to the logger\nlogger.addHandler(fh)\nlogger.addHandler(ch)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"f4ec2bd8-4d95-498c-8be2-66a56c6dce49","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["/tmp/custom_log2023-03-15-13-52-40.log\n"]}],"execution_count":0},{"cell_type":"code","source":["#dbutils.help()\n#dbutils.fs.help()\n#display(dbutils.fs.ls(\"file:/tmp/\"))\n#dbutils.fs.mkdirs(\"/FileStore/custom_logging/\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"688ecbe2-db55-4955-9b94-c8bfeb5b5932","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"74a16a2e-559c-4d77-b390-2870da0d74e7","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[29]: True"]}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0b280c63-7b2a-44a3-bd62-050a07845cdc","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"custom_logging","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3458014698622273}},"nbformat":4,"nbformat_minor":0}
